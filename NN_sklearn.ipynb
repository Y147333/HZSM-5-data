{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#载入数据\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "data_frame=pd.read_excel(\"total.xlsx\")\n",
    "df = data_frame.T #转置矩阵，因为dataFrame中每个结构的数据是以列排布的\n",
    "dfs = shuffle(df.iloc[1:,:]) #对数据进行打乱，同时去除第一行\n",
    "dfs = dfs.reset_index(drop=True) #重新设置索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#划分训练集与测试集\n",
    "x_train = dfs.iloc[1:2197,:30263]\n",
    "x_test = dfs.iloc[2197:,:30263]\n",
    "y_train = dfs.iloc[1:2197,30264]\n",
    "y_test = dfs.iloc[2197:,30264]\n",
    "print(\"Size of training set:{} size of testing set:{}\".format(x_train.shape[0],x_test.shape[0]))\n",
    "\n",
    "# 对目标进行归一化 y = (y'-min(y'))/(max(y')-min(y'))\n",
    "a = max(y_train)\n",
    "b = min(y_train)\n",
    "delta = a-b\n",
    "y_train2 = (y_train-b)/delta\n",
    "y_test2 = (y_test-b)/delta\n",
    "\n",
    "# grid search\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "best_score = 0\n",
    "best_parameters = {'solver':'lbfgs','hidden_layer_sizes':(100,100),'activation':'identity'}\n",
    "for hid_lay in [(100,100),(10,10),(100,100,100),(10,10,10),(100,100,100,100),(10,10,10,10)]:\n",
    "    for activate in ['identity','logistic','tanh','relu']:\n",
    "        for sover in ['lbfgs','sgd','adam']:\n",
    "            mlp = MLPRegressor(solver=sover,hidden_layer_sizes=hid_lay,activation=activate,alpha=0.01)#对于每种参数可能的组合，进行一次训练；\n",
    "            scores = cross_val_score(mlp,x_train,y_train2,cv=5,scoring = 'r2')\n",
    "            score = scores.mean() #取平均数\n",
    "            print('solver: ',sover.rjust(5),'\\n','hidden_layer_sizes: ',hid_lay,'\\n','activation:',activate.rjust(9),'\\n','score:',score,'\\n','\\n')\n",
    "            if score > best_score:#找到表现最好的参数\n",
    "                best_score = score\n",
    "                best_parameters = {'solver':sover,'hidden_layer_sizes':hid_lay,'activation':activate}\n",
    "\n",
    "mlp = MLPRegressor(**best_parameters,alpha=0.01)\n",
    "mlp.fit(x_train,y_train2)\n",
    "test_score = mlp.score(x_test,y_test2)\n",
    "print(\"Best score on validation set:{:.2f}\".format(best_score))\n",
    "print(\"Best parameters:{}\".format(best_parameters))\n",
    "print(\"Score on testing set:{:.2f}\".format(test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#基于随机森林的预测\n",
    "best_score2 = 0 # grid search\n",
    "best_parameters2 = {'max_depth':2,'max_features':3,'min_samples_leaf':2} # 优化算法（solver），隐含层结构（hidden_layer_sizes），激活函数（activation）\n",
    "for i in [2,3,4]:\n",
    "    for j in [2,3,4]:\n",
    "        for k in [2,3,4]:\n",
    "            regr = RandomForestRegressor(max_depth=i,max_features=j,min_samples_leaf=k)\n",
    "            scores = cross_val_score(regr,x_train,y_train,cv=5,scoring = 'r2')# ‘cv=5’表示进行五折交叉验证，scoring = 'r2'表示以R2作为评估参数，评估参数rmse,mse\n",
    "            score = scores.mean() #取平均数\n",
    "            print('max_depth: ',i,'\\n','max_features: ',j,'\\n','min_samples_leaf:',k,'\\n','score:',score,'\\n','\\n')\n",
    "            if score > best_score2:#找到表现最好的参数\n",
    "                best_score2 = score\n",
    "                best_parameters2 = {'max_depth':i,'max_features':j,'min_samples_leaf':k}\n",
    "\n",
    "\n",
    "\n",
    "regr = RandomForestRegressor(**best_parameters2)\n",
    "# regr = RandomForestRegressor(random_state=100,\n",
    "#                              bootstrap=True,\n",
    "#                              max_depth=2,\n",
    "#                              max_features=2,\n",
    "#                              min_samples_leaf=3,\n",
    "#                              min_samples_split=5,\n",
    "#                              n_estimators=3)\n",
    "regr.fit(x_train, y_train)\n",
    "y_pre2 = regr.predict(x_test)\n",
    "test_score = regr.score(x_test,y_test)\n",
    "print(\"Best score on validation set:{:.2f}\".format(best_score2))\n",
    "print(\"Best parameters:{}\".format(best_parameters2))\n",
    "print(\"Score on testing set:{:.2f}\".format(test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "xx=range(0,len(y_test2))\n",
    "pred_y = mlp.predict(x_test)\n",
    "plt.figure(figsize=(18,6))\n",
    "plt.scatter(xx,y_test2,color=\"red\",label=\"Sample Point\",linewidth=3) \n",
    "plt.plot(xx,pred_y,color=\"orange\",label=\"Fitting Line\",linewidth=2)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-39b053eba3b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# 模型拟合数据\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mfeat_importances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# 筛选出特征的重要性程度最大的10个特征\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "# 模型拟合数据\n",
    "clf.fit(x_train,y_train2).astype()\n",
    "feat_importances = pd.Series(clf.feature_importances_, index=x_train.columns)\n",
    "# 筛选出特征的重要性程度最大的10个特征\n",
    "feat_importances.nlargest(10).plot(kind='barh', figsize = (8, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_friedman1\n",
    "# from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.inspection import plot_partial_dependence\n",
    "\n",
    "# clf = GradientBoostingRegressor(n_estimators=10).fit(X, y)\n",
    "plot_partial_dependence(mlp, features=[0, 2],X=df.iloc[1:,:10799],grid_resolution=10)  \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(selectors.generation_scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_rf_train = x_train.values\n",
    "y_rf_train = y_train2.values\n",
    "x_rf_test = x_test.values\n",
    "y_rf_test = y_test2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练随机森林解决回归问题\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "regressor = RandomForestRegressor(n_estimators=200, random_state=0)\n",
    "regressor.fit(x_rf_train, y_rf_train)\n",
    "y_pred = regressor.predict(x_rf_test)\n",
    "\n",
    "# 评估回归性能\n",
    "from sklearn import metrics\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_rf_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_rf_test, y_pred))\n",
    "print('Root Mean Squared Error:',\n",
    "      np.sqrt(metrics.mean_squared_error(y_rf_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.r2_score(y_rf_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets as datasets\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "regr = RandomForestRegressor()\n",
    "# regr = RandomForestRegressor(random_state=100,\n",
    "#                              bootstrap=True,\n",
    "#                              max_depth=2,\n",
    "#                              max_features=2,\n",
    "#                              min_samples_leaf=3,\n",
    "#                              min_samples_split=5,\n",
    "#                              n_estimators=3)\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('reduce_dim', PCA()),\n",
    "                 ('regressor', regr)])\n",
    "pipe.fit(x_rf_train, y_rf_train)\n",
    "ypipe = pipe.predict(x_rf_test)\n",
    "\n",
    "from six import StringIO\n",
    "from IPython.display import Image\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "import os\n",
    "\n",
    "# 执行一次\n",
    "# os.environ['PATH'] = os.environ['PATH']+';'+r\"D:\\CLibrary\\Graphviz2.44.1\\bin\\graphviz\"\n",
    "dot_data = StringIO()\n",
    "export_graphviz(pipe.named_steps['regressor'].estimators_[0],\n",
    "                out_file=dot_data)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "graph.write_png('tree.png')\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature importance\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "importances = regressor.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in regressor.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(x_rf_train.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(x_rf_train.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(x_rf_train.shape[1]), indices)\n",
    "plt.xlim([-1, x_rf_train.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "explainer = shap.TreeExplainer(regressor) #这里的model在准备工作中已经完成建模，模型名称就是model\n",
    "shap_values = explainer.shap_values(x_rf_test) #这里的test_data是我的测试集，predictors是X_train的变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, x_rf_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
